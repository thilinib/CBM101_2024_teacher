{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn Classification with  k-nearest Neighbors classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key points from the previous notebooks:\n",
    "- It is ideal to explore and visualize the data prior to doing actual machine learning.\n",
    "- A model must be instantiated, trained using `.fit` and used to predict using `.predict`.\n",
    "- You must train your model and test it on separate data. `train_test_split` is a function used for this purpose.\n",
    "- Metrics for evaluation exist, like accuracy, sensitivity and specificity. More nuances method like the confusion matrix and AUC (not covered yet) are also very useful. `classification_report` gives a neat summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/thilinib/CBM101/main/E_Macine_Learning/data/preprocessed_diabetes.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Outcome'])\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# K-Nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors=5) # define the model and specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train) # train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like that the model is trained, in two lines of code. Now you are left with a trained algorithm `clf`, which you can use to predict the group belonging of new samples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred, average='binary')\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have done minimal preprocessing. With few exceptions, you should always do some basic preprocessing, like standardizing each input feature to zero mean and unit variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the `fit` method, many `sklearn` objects have a `transform` method, which lets you transform your dataset. In this case, the transform yields the dataset post normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler.fit(X_train) # fit only the training set\n",
    "X_train_scaled = scaler.transform(X_train) #transform the training dataset\n",
    "X_scaled = scaler.transform(X) # For visualization purposes, let's also transform the full dataset (X)\n",
    "\n",
    "# Plot before and after normalization\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)  # Make two plots on the same row\n",
    "ax[0].scatter(X.iloc[:, 0], X.iloc[:, 1], c=y)  # Use iloc to select the first two columns of X\n",
    "ax[0].set_title('Before normalizing')  # Set the title of the first subplot\n",
    "ax[1].scatter(X_scaled[:, 0], X_scaled[:, 1], c=y)  # Use the transformed X\n",
    "ax[1].set_title('After normalizing')  # Set the title of the second subplot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:  you have to fit the scaler to the training set (not the whole dataset, X), and then transform `X_test` and `X_train` later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data again in to X and y\n",
    "X = df.drop(columns=['Outcome'])\n",
    "y = df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)#split to training and test\n",
    "scaler.fit(X_train) ## Fit the scaler on the training set\n",
    "\n",
    "## Transform both the training and testing set\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#adding power transformation to training and testing set\n",
    "pt = PowerTransformer()\n",
    "X_train = pt.fit_transform(X_train)\n",
    "X_test = pt.fit_transform(X_test)\n",
    "\n",
    "# train the model with cross validation (using gridsearch)\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "parameters = {}\n",
    "clf_cv = GridSearchCV(clf, cv = 10, param_grid =parameters)\n",
    "clf_cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tune the model using GridSearchCV which will help you to find the best parameters of the model. Also it helps you to do cross validation at the same time.\n",
    "[link](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = clf_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,  recall_score, precision_score, f1_score\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred, average='binary')\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common pitfalls and recommended practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inconsistent preprocessing\n",
    "    - Instead of passing the non-transformed X_test to predict, we should transform the test data, the same way we transformed the training data:\n",
    "2. Data leakage\n",
    "    - Data leakage occurs when information that would not be available at prediction time is used when building the model. The general rule is to never call fit on the test data\n",
    "    - Although both train and test data subsets should receive the same preprocessing transformation (as described in the previous section), it is important that these transformations are only learnt from the training data. \n",
    "3. Controlling randomness\n",
    "    - Not controlling randomness, leading to non-reproducible results. Use random_state parameter to control the randomness for reproducibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
